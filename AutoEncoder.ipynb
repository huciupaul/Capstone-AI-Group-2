{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfee64004020ddf8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reinm\\anaconda3\\envs\\precursor_legacy\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60faf1bcc66cef9b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # set cores for numpy\n",
    "import numpy as np\n",
    "import json\n",
    "tf.get_logger().setLevel('ERROR') # no info and warnings are printed \n",
    "tf.config.threading.set_inter_op_parallelism_threads(1) # set cores for TF\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# tf.config.set_visible_devices([], 'GPU') #runs the code without GPU\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib as mpl\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "#Latex\n",
    "mpl.rc('text', usetex = True)\n",
    "mpl.rc('font', family = 'serif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927fe4f2d90758e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf3de97e6910cb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ceda566dd0d31a7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the HDF5 file: ['dissipation_rates', 'kinetic_energy', 'velocity_field']\n",
      "Shape of the velocity field: (3000, 48, 48, 2)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TODO: Update parameters\n",
    "TODO: remove transient as it was not saved when we generated data\n",
    "'''\n",
    "\n",
    "downsample = 1\n",
    "Re       = 30\n",
    "data_len = 3000\n",
    "transient = 200 # Number of transient steps to ignore from our data\n",
    "Nx = 48\n",
    "Nu = 2\n",
    "# Generate this from Gen_data.ipynb\n",
    "# fln = '/data/ar994/Python/data/Kolmogorov/Kolmogorov_0.1_48_30.0_100100_32.h5'\n",
    "fln = 'Generated_data.h5'\n",
    "hf  = h5py.File(fln,'r')\n",
    "dt  = 0.1\n",
    "\n",
    "# Check the contents of the HDF5 file\n",
    "print(\"Contents of the HDF5 file:\", list(hf.keys()))\n",
    "\n",
    "U = np.array(hf.get('velocity_field')[transient:transient+data_len:downsample], dtype=np.float32)\n",
    "hf.close()\n",
    "\n",
    "# Check the lenght of the velocity field\n",
    "print(\"Shape of the velocity field:\", U.shape)  \n",
    "# So, the velocity field has 3000 samples, each sample has 48x48 grid points and each grid point has 2 components (ux,uy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad809402ca51b84",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of grid points in x direction: 48\n",
      "Number of grid points in y direction: 48\n"
     ]
    }
   ],
   "source": [
    "N_x     = U.shape[1] \n",
    "print(\"Number of grid points in x direction:\", N_x)\n",
    "N_y     = U.shape[2]\n",
    "print(\"Number of grid points in y direction:\", N_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c6d5934ac3579",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data batching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a22f0e305d98448",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_data(U, b_size, n_batches):\n",
    "    \n",
    "    '''\n",
    "    Splits the data in batches. Each batch is created by sampling the signal with interval\n",
    "    equal to n_batches\n",
    "    '''\n",
    "    data   = np.zeros((n_batches, b_size, U.shape[1], U.shape[2], U.shape[3]))    \n",
    "    for i in range(n_batches):\n",
    "        data[i] = U[i::n_batches].copy()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23101c0562d8ab9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data used for training: 83.33333333333334\n",
      "Percentage of data used for validation: 16.666666666666668\n"
     ]
    }
   ],
   "source": [
    "b_size      = 50   #batch_size\n",
    "n_batches   = data_len//b_size  #number of batches\n",
    "\n",
    "train_batches = int(n_batches*(5/6))\n",
    "val_batches = int(n_batches*(1/6))\n",
    "\n",
    "print(\"Percentage of data used for training:\", 100*(1-val_batches/n_batches))\n",
    "print(\"Percentage of data used for validation:\", 100*val_batches/n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890776f3731ddf5f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data before batching: (2500, 48, 48, 2)\n",
      "Shape of the training data after batching: (50, 50, 48, 48, 2) \n",
      "\n",
      "Shape of the validation data before batching: (500, 48, 48, 2)\n",
      "Shape of the validation data after batching: (10, 50, 48, 48, 2)\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "U_tt        = np.array(U[:train_batches*b_size].copy())            #to be used for random batches\n",
    "print(\"Shape of the training data before batching:\", U_tt.shape)\n",
    "U_train     = batch_data(U_tt, b_size, train_batches).astype('float32') #to be used for randomly shuffled batches\n",
    "print(\"Shape of the training data after batching:\", U_train.shape, \"\\n\")\n",
    "\n",
    "# validation data\n",
    "U_vv        = np.array(U[train_batches*b_size:\n",
    "                         train_batches*b_size+b_size*val_batches].copy())\n",
    "print(\"Shape of the validation data before batching:\", U_vv.shape)\n",
    "U_val       = batch_data(U_vv, b_size, val_batches).astype('float32')         \n",
    "print(\"Shape of the validation data after batching:\", U_val.shape)   \n",
    "\n",
    "# Delete the original data to save memory:\n",
    "del U_tt, U_vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879234b2b19161c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Autoencoder Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e5f94935abd91d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Changes: included loss mse and optimizer as inputs to train_step\n",
    "'''\n",
    "#@tf.function #this creates the tf graph\n",
    "def model(inputs, enc_mods, dec_mods, is_train=False):\n",
    "    \n",
    "    '''\n",
    "    Multiscale autoencoder, taken from Hasegawa 2020. The contribution of the CNNs at different\n",
    "    scales are simply summed.\n",
    "    '''\n",
    "        \n",
    "    # sum of the contributions of the different CNNs\n",
    "    encoded = 0\n",
    "    for enc_mod in enc_mods:\n",
    "        encoded += enc_mod(inputs, training=is_train)\n",
    "            \n",
    "    decoded = 0\n",
    "    for dec_mod in dec_mods:\n",
    "        decoded += dec_mod(encoded, training=is_train)\n",
    "        \n",
    "    return encoded, decoded\n",
    "\n",
    "\n",
    "#@tf.function #this creates the tf graph\n",
    "def train_step(inputs, enc_mods, dec_mods, Loss_Mse, optimizer, train=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Trains the model by minimizing the loss between input and output\n",
    "    \"\"\"\n",
    "    \n",
    "    # autoencoded field\n",
    "    decoded  = model(inputs, enc_mods, dec_mods, is_train=train)[-1]\n",
    "\n",
    "    # loss with respect to the data\n",
    "    loss = Loss_Mse(inputs, decoded)\n",
    "    \n",
    "    # compute and apply gradients inside tf.function environment for computational efficiency\n",
    "    if train:\n",
    "        # create a variable with all the weights to perform gradient descent on\n",
    "        # appending lists is done by plus sign\n",
    "        varss = [] #+ Dense.trainable_weights\n",
    "        for enc_mod in enc_mods:\n",
    "            varss  += enc_mod.trainable_weights\n",
    "        for dec_mod in dec_mods:\n",
    "            varss +=  dec_mod.trainable_weights\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            decoded  = model(inputs, enc_mods, dec_mods, is_train=train)[-1]\n",
    "            loss = Loss_Mse(inputs, decoded)\n",
    "        grads = tape.gradient(loss, varss)\n",
    "        optimizer.apply_gradients(zip(grads, varss))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a2c27782f3dc56",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def periodic_padding(image, padding=1, asym=False):\n",
    "    '''\n",
    "    Create a periodic padding (same of np.pad('wrap')) around the image, \n",
    "    to mimic periodic boundary conditions.\n",
    "    When asym=True on the right and lower edges an additional column/row is added\n",
    "    '''\n",
    "        \n",
    "    if asym:\n",
    "        lower_pad = image[:,:padding+1,:]\n",
    "    else:\n",
    "        lower_pad = image[:,:padding,:]\n",
    "    \n",
    "    if padding != 0:\n",
    "        upper_pad     = image[:,-padding:,:]\n",
    "        partial_image = tf.concat([upper_pad, image, lower_pad], axis=1)\n",
    "    else:\n",
    "        partial_image = tf.concat([image, lower_pad], axis=1)\n",
    "        \n",
    "    if asym:\n",
    "        right_pad = partial_image[:,:,:padding+1] \n",
    "    else:\n",
    "        right_pad = partial_image[:,:,:padding]\n",
    "    \n",
    "    if padding != 0:\n",
    "        left_pad = partial_image[:,:,-padding:]\n",
    "        padded_image = tf.concat([left_pad, partial_image, right_pad], axis=2)\n",
    "    else:\n",
    "        padded_image = tf.concat([partial_image, right_pad], axis=2)\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2f5299236c25069",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PerPad2D(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Periodic Padding layer\n",
    "    \"\"\"\n",
    "    def __init__(self, padding=1, asym=False, **kwargs):\n",
    "        self.padding = padding\n",
    "        self.asym    = asym\n",
    "        super(PerPad2D, self).__init__(**kwargs)\n",
    "        \n",
    "    def get_config(self): #needed to be able to save and load the model with this layer\n",
    "        config = super(PerPad2D, self).get_config()\n",
    "        config.update({\n",
    "            'padding': self.padding,\n",
    "            'asym': self.asym,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x):\n",
    "        return periodic_padding(x, self.padding, self.asym)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08e201bf0dd289",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "401b86b6b0639604",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: What is lat_dep?\n",
    "TODO: hyperparameter tuning\n",
    "TODO: update N_latent\n",
    "'''\n",
    "\n",
    "# define the model\n",
    "# we do not have pooling and upsampling, instead we use stride=2\n",
    "\n",
    "lat_dep       = 2                          #latent space depth, if we want to include dissipation rate and vorticity, increase this number\n",
    "n_fil         = [6,12,24,lat_dep]          #number of filters encoder\n",
    "n_dec         = [24,12,6,3]                #number of filters decoder\n",
    "N_parallel    = 3                          #number of parallel CNNs for multiscale\n",
    "ker_size      = [(3,3), (5,5), (7,7)]      #kernel sizes\n",
    "N_layers      = 4                          #number of layers in every CNN\n",
    "act           = 'tanh'                     #activation function\n",
    "\n",
    "pad_enc       = 'valid'         #no padding in the conv layer\n",
    "pad_dec       = 'valid'\n",
    "p_size        = [0,1,2]         #stride = 2 periodic padding size          \n",
    "p_fin         = [1,2,3]         #stride = 1 periodic padding size\n",
    "p_dec         = 1               #padding in the first decoder layer\n",
    "p_crop        = U.shape[1]      #crop size of the output equal to input size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9b1599575fd10b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize the encoders and decoders with different kernel sizes    \n",
    "enc_mods      = [None]*(N_parallel)\n",
    "dec_mods      = [None]*(N_parallel)    \n",
    "for i in range(N_parallel):\n",
    "    enc_mods[i] = tf.keras.Sequential(name='Enc_' + str(i))\n",
    "    dec_mods[i] = tf.keras.Sequential(name='Dec_' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d6a2f58552fa24",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate encoder layers    \n",
    "for j in range(N_parallel):\n",
    "    for i in range(N_layers):      \n",
    "\n",
    "        #stride=2 padding and conv\n",
    "        enc_mods[j].add(PerPad2D(padding=p_size[j], asym=True,\n",
    "                                          name='Enc_' + str(j)+'_PerPad_'+str(i)))\n",
    "        enc_mods[j].add(tf.keras.layers.Conv2D(filters = n_fil[i], kernel_size=ker_size[j],\n",
    "                                      activation=act, padding=pad_enc, strides=2,\n",
    "                        name='Enc_' + str(j)+'_ConvLayer_'+str(i)))\n",
    "\n",
    "        #stride=1 padding and conv\n",
    "        if i<N_layers-1:\n",
    "            enc_mods[j].add(PerPad2D(padding=p_fin[j], asym=False,\n",
    "                                                      name='Enc_'+str(j)+'_Add_PerPad1_'+str(i)))\n",
    "            enc_mods[j].add(tf.keras.layers.Conv2D(filters=n_fil[i],\n",
    "                                                    kernel_size=ker_size[j], \n",
    "                                                activation=act,padding=pad_dec,strides=1,\n",
    "                                                    name='Enc_'+str(j)+'_Add_Layer1_'+str(i)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1beb0a62c6bf7543",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 2\n",
      "Size of the latent space: 18\n"
     ]
    }
   ],
   "source": [
    "#explicitly obtain the size of the latent space\n",
    "N_1      = enc_mods[-1](U_train[0]).shape\n",
    "N_latent = N_1[-3]*N_1[-2]*N_1[-1]\n",
    "print(N_1[-3], N_1[-2], N_1[-1])\n",
    "print(\"Size of the latent space:\", N_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c854b595c114f84",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate decoder layers            \n",
    "for j in range(N_parallel):\n",
    "\n",
    "    for i in range(N_layers):\n",
    "\n",
    "        #initial padding of latent space\n",
    "        if i==0: \n",
    "            dec_mods[j].add(PerPad2D(padding=p_dec, asym=False,\n",
    "                                          name='Dec_' + str(j)+'_PerPad_'+str(i))) \n",
    "        \n",
    "        #Transpose convolution with stride = 2 \n",
    "        dec_mods[j].add(tf.keras.layers.Conv2DTranspose(filters = n_dec[i],\n",
    "                                       output_padding=None,kernel_size=ker_size[j],\n",
    "                                      activation=act, padding=pad_dec, strides=2,\n",
    "                            name='Dec_' + str(j)+'_ConvLayer_'+str(i)))\n",
    "        \n",
    "        #Convolution with stride=1\n",
    "        if  i<N_layers-1:       \n",
    "            dec_mods[j].add(tf.keras.layers.Conv2D(filters=n_dec[i],\n",
    "                                        kernel_size=ker_size[j], \n",
    "                                       activation=act,padding=pad_dec,strides=1,\n",
    "                                      name='Dec_' + str(j)+'_ConvLayer1_'+str(i)))\n",
    "\n",
    "    #crop and final linear convolution with stride=1\n",
    "    dec_mods[j].add(tf.keras.layers.CenterCrop(p_crop + 2*p_fin[j],\n",
    "                                                   p_crop+ 2*p_fin[j],\n",
    "                            name='Dec_' + str(j)+'_Crop_'+str(i)))\n",
    "    dec_mods[j].add(tf.keras.layers.Conv2D(filters=U.shape[3],\n",
    "                                            kernel_size=ker_size[j], \n",
    "                                            activation='linear',padding=pad_dec,strides=1,\n",
    "                                              name='Dec_' + str(j)+'_Final_Layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14958102f40640fe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent space size: 18\n",
      "physical space size: (4608,)\n",
      "\n",
      "Model: \"Enc_0\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Enc_0_PerPad_0 (PerPad2D)   (50, 49, 49, 2)           0         \n",
      "                                                                 \n",
      " Enc_0_ConvLayer_0 (Conv2D)  (50, 24, 24, 6)           114       \n",
      "                                                                 \n",
      " Enc_0_Add_PerPad1_0 (PerPad  (50, 26, 26, 6)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Enc_0_Add_Layer1_0 (Conv2D)  (50, 24, 24, 6)          330       \n",
      "                                                                 \n",
      " Enc_0_PerPad_1 (PerPad2D)   (50, 25, 25, 6)           0         \n",
      "                                                                 \n",
      " Enc_0_ConvLayer_1 (Conv2D)  (50, 12, 12, 12)          660       \n",
      "                                                                 \n",
      " Enc_0_Add_PerPad1_1 (PerPad  (50, 14, 14, 12)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Enc_0_Add_Layer1_1 (Conv2D)  (50, 12, 12, 12)         1308      \n",
      "                                                                 \n",
      " Enc_0_PerPad_2 (PerPad2D)   (50, 13, 13, 12)          0         \n",
      "                                                                 \n",
      " Enc_0_ConvLayer_2 (Conv2D)  (50, 6, 6, 24)            2616      \n",
      "                                                                 \n",
      " Enc_0_Add_PerPad1_2 (PerPad  (50, 8, 8, 24)           0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Enc_0_Add_Layer1_2 (Conv2D)  (50, 6, 6, 24)           5208      \n",
      "                                                                 \n",
      " Enc_0_PerPad_3 (PerPad2D)   (50, 7, 7, 24)            0         \n",
      "                                                                 \n",
      " Enc_0_ConvLayer_3 (Conv2D)  (50, 3, 3, 2)             434       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,670\n",
      "Trainable params: 10,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Enc_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Enc_1_PerPad_0 (PerPad2D)   (50, 51, 51, 2)           0         \n",
      "                                                                 \n",
      " Enc_1_ConvLayer_0 (Conv2D)  (50, 24, 24, 6)           306       \n",
      "                                                                 \n",
      " Enc_1_Add_PerPad1_0 (PerPad  (50, 28, 28, 6)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Enc_1_Add_Layer1_0 (Conv2D)  (50, 24, 24, 6)          906       \n",
      "                                                                 \n",
      " Enc_1_PerPad_1 (PerPad2D)   (50, 27, 27, 6)           0         \n",
      "                                                                 \n",
      " Enc_1_ConvLayer_1 (Conv2D)  (50, 12, 12, 12)          1812      \n",
      "                                                                 \n",
      " Enc_1_Add_PerPad1_1 (PerPad  (50, 16, 16, 12)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Enc_1_Add_Layer1_1 (Conv2D)  (50, 12, 12, 12)         3612      \n",
      "                                                                 \n",
      " Enc_1_PerPad_2 (PerPad2D)   (50, 15, 15, 12)          0         \n",
      "                                                                 \n",
      " Enc_1_ConvLayer_2 (Conv2D)  (50, 6, 6, 24)            7224      \n",
      "                                                                 \n",
      " Enc_1_Add_PerPad1_2 (PerPad  (50, 10, 10, 24)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Enc_1_Add_Layer1_2 (Conv2D)  (50, 6, 6, 24)           14424     \n",
      "                                                                 \n",
      " Enc_1_PerPad_3 (PerPad2D)   (50, 9, 9, 24)            0         \n",
      "                                                                 \n",
      " Enc_1_ConvLayer_3 (Conv2D)  (50, 3, 3, 2)             1202      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,486\n",
      "Trainable params: 29,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Enc_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Enc_2_PerPad_0 (PerPad2D)   (50, 53, 53, 2)           0         \n",
      "                                                                 \n",
      " Enc_2_ConvLayer_0 (Conv2D)  (50, 24, 24, 6)           594       \n",
      "                                                                 \n",
      " Enc_2_Add_PerPad1_0 (PerPad  (50, 30, 30, 6)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Enc_2_Add_Layer1_0 (Conv2D)  (50, 24, 24, 6)          1770      \n",
      "                                                                 \n",
      " Enc_2_PerPad_1 (PerPad2D)   (50, 29, 29, 6)           0         \n",
      "                                                                 \n",
      " Enc_2_ConvLayer_1 (Conv2D)  (50, 12, 12, 12)          3540      \n",
      "                                                                 \n",
      " Enc_2_Add_PerPad1_1 (PerPad  (50, 18, 18, 12)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Enc_2_Add_Layer1_1 (Conv2D)  (50, 12, 12, 12)         7068      \n",
      "                                                                 \n",
      " Enc_2_PerPad_2 (PerPad2D)   (50, 17, 17, 12)          0         \n",
      "                                                                 \n",
      " Enc_2_ConvLayer_2 (Conv2D)  (50, 6, 6, 24)            14136     \n",
      "                                                                 \n",
      " Enc_2_Add_PerPad1_2 (PerPad  (50, 12, 12, 24)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Enc_2_Add_Layer1_2 (Conv2D)  (50, 6, 6, 24)           28248     \n",
      "                                                                 \n",
      " Enc_2_PerPad_3 (PerPad2D)   (50, 11, 11, 24)          0         \n",
      "                                                                 \n",
      " Enc_2_ConvLayer_3 (Conv2D)  (50, 3, 3, 2)             2354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,710\n",
      "Trainable params: 57,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Dec_0\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dec_0_PerPad_0 (PerPad2D)   (50, 5, 5, 2)             0         \n",
      "                                                                 \n",
      " Dec_0_ConvLayer_0 (Conv2DTr  (50, 11, 11, 24)         456       \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_0_ConvLayer1_0 (Conv2D)  (50, 9, 9, 24)           5208      \n",
      "                                                                 \n",
      " Dec_0_ConvLayer_1 (Conv2DTr  (50, 19, 19, 12)         2604      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_0_ConvLayer1_1 (Conv2D)  (50, 17, 17, 12)         1308      \n",
      "                                                                 \n",
      " Dec_0_ConvLayer_2 (Conv2DTr  (50, 35, 35, 6)          654       \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_0_ConvLayer1_2 (Conv2D)  (50, 33, 33, 6)          330       \n",
      "                                                                 \n",
      " Dec_0_ConvLayer_3 (Conv2DTr  (50, 67, 67, 3)          165       \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_0_Crop_3 (CenterCrop)   (50, 50, 50, 3)           0         \n",
      "                                                                 \n",
      " Dec_0_Final_Layer (Conv2D)  (50, 48, 48, 2)           56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,781\n",
      "Trainable params: 10,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Dec_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dec_1_PerPad_0 (PerPad2D)   (50, 5, 5, 2)             0         \n",
      "                                                                 \n",
      " Dec_1_ConvLayer_0 (Conv2DTr  (50, 13, 13, 24)         1224      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_1_ConvLayer1_0 (Conv2D)  (50, 9, 9, 24)           14424     \n",
      "                                                                 \n",
      " Dec_1_ConvLayer_1 (Conv2DTr  (50, 21, 21, 12)         7212      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_1_ConvLayer1_1 (Conv2D)  (50, 17, 17, 12)         3612      \n",
      "                                                                 \n",
      " Dec_1_ConvLayer_2 (Conv2DTr  (50, 37, 37, 6)          1806      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_1_ConvLayer1_2 (Conv2D)  (50, 33, 33, 6)          906       \n",
      "                                                                 \n",
      " Dec_1_ConvLayer_3 (Conv2DTr  (50, 69, 69, 3)          453       \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_1_Crop_3 (CenterCrop)   (50, 52, 52, 3)           0         \n",
      "                                                                 \n",
      " Dec_1_Final_Layer (Conv2D)  (50, 48, 48, 2)           152       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,789\n",
      "Trainable params: 29,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Dec_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dec_2_PerPad_0 (PerPad2D)   (50, 5, 5, 2)             0         \n",
      "                                                                 \n",
      " Dec_2_ConvLayer_0 (Conv2DTr  (50, 15, 15, 24)         2376      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_2_ConvLayer1_0 (Conv2D)  (50, 9, 9, 24)           28248     \n",
      "                                                                 \n",
      " Dec_2_ConvLayer_1 (Conv2DTr  (50, 23, 23, 12)         14124     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_2_ConvLayer1_1 (Conv2D)  (50, 17, 17, 12)         7068      \n",
      "                                                                 \n",
      " Dec_2_ConvLayer_2 (Conv2DTr  (50, 39, 39, 6)          3534      \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_2_ConvLayer1_2 (Conv2D)  (50, 33, 33, 6)          1770      \n",
      "                                                                 \n",
      " Dec_2_ConvLayer_3 (Conv2DTr  (50, 71, 71, 3)          885       \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " Dec_2_Crop_3 (CenterCrop)   (50, 54, 54, 3)           0         \n",
      "                                                                 \n",
      " Dec_2_Final_Layer (Conv2D)  (50, 48, 48, 2)           296       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,301\n",
      "Trainable params: 58,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# run the model once to print summary\n",
    "enc0, dec0 = model(U_train[0], enc_mods, dec_mods)\n",
    "print('latent space size:', N_latent)\n",
    "print('physical space size:', U[0].flatten().shape)\n",
    "print('')\n",
    "for j in range(3):\n",
    "    enc_mods[j].summary()\n",
    "for j in range(3):\n",
    "    dec_mods[j].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da56cc49b2da96",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97c3210b82d433",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'''\n",
    "TODO: change path\n",
    "TODO: change get_weights to save_parameters\n",
    "'''\n",
    "n_epochs = 2\n",
    "rng = np.random.default_rng() #random generator for later shufflinh\n",
    "\n",
    "# plotting and saving\n",
    "plt.rcParams[\"figure.figsize\"] = (15,4)\n",
    "plt.rcParams[\"font.size\"]  = 20\n",
    "path = './data/48_RE30_'+str(N_latent) #to save model\n",
    "\n",
    "\n",
    "#define loss, optimizer and initial learning rate   \n",
    "Loss_Mse    = tf.keras.losses.MeanSquaredError()\n",
    "optimizer   = tf.keras.optimizers.Adam(amsgrad=True) #amsgrad True for better convergence\n",
    "\n",
    "l_rate      = 0.002\n",
    "optimizer.learning_rate = l_rate\n",
    "lrate_update = True     # flag for l_rate updating\n",
    "lrate_mult   = 0.75     # decrease by this factore the l_rate \n",
    "N_lr         = 100      # number of epochs before which the l_rate is not updated\n",
    "\n",
    "# quantities to check and store the training and validation loss and the training goes on\n",
    "old_loss      = np.zeros(n_epochs)      # needed to evaluate training loss convergence to update l_rate\n",
    "tloss_plot    = np.zeros(n_epochs)      # training loss\n",
    "vloss_plot    = np.zeros(n_epochs)      # validation loss\n",
    "old_loss[0]   = 1e6                      # initial value has to be high\n",
    "N_check       = 1                        # each N_check epochs we check convergence and validation loss\n",
    "patience      = 200                      # if the val_loss has not gone down in the last patience epochs, early stop\n",
    "last_save     = patience\n",
    "t             = 1                        # initial (not important value) to monitor the time of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf216a22e1f8e1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ; Train_Loss 0.3132314682006836 ; Val_Loss 0.12248467206954956 ; Ratio 0.3910356541542471\n",
      "Time per epoch 1736418748.1422608\n",
      "\n",
      "Epoch 1 ; Train_Loss 0.12255351066589355 ; Val_Loss 0.07160788774490356 ; Ratio 0.5842989511750635\n",
      "Time per epoch 21.671221017837524\n",
      "\n",
      "Saving Model..\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "n_batches   = min(n_batches, len(U_train))  # Ensure n_batches does not exceed the size of U_train\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    if epoch - last_save > patience: break #early stop\n",
    "                \n",
    "    #Perform gradient descent for all the batches every epoch\n",
    "    loss_0 = 0\n",
    "    rng.shuffle(U_train, axis=0) #shuffle batches\n",
    "    for j in range(train_batches):\n",
    "        loss    = train_step(U_train[j], enc_mods, dec_mods, Loss_Mse, optimizer)\n",
    "        loss_0 += loss\n",
    "    \n",
    "    #save train loss\n",
    "    tloss_plot[epoch]  = loss_0.numpy()/train_batches\n",
    "    \n",
    "    # every N epochs checks the convergence of the training loss and val loss\n",
    "    if (epoch%N_check==0):\n",
    "        \n",
    "        #Compute Validation Loss\n",
    "        loss_val        = 0\n",
    "        for j in range(val_batches):\n",
    "            loss        = train_step(U_val[j], enc_mods, dec_mods, Loss_Mse, optimizer, train=False)\n",
    "            loss_val   += loss\n",
    "        \n",
    "        #save validation loss\n",
    "        vloss_plot[epoch]  = loss_val.numpy()/val_batches \n",
    "        \n",
    "        # Decreases the learning rate if the training loss is not going down with respect to \n",
    "        # N_lr epochs before\n",
    "        if epoch > N_lr and lrate_update:\n",
    "            #check if the training loss is smaller than the average training loss N_lr epochs ago\n",
    "            tt_loss   = np.mean(tloss_plot[epoch-N_lr:epoch])\n",
    "            if tt_loss > old_loss[epoch-N_lr]:\n",
    "                #if it is larger, load optimal val loss weights and decrease learning rate\n",
    "                print('LOADING MINIMUM')\n",
    "                for i in range(N_parallel):\n",
    "                    enc_mods[i].load_weights(path + '/enc_mod'+str(ker_size[i])+'_'+str(N_latent)+'_weights.h5')\n",
    "                    dec_mods[i].load_weights(path + '/dec_mod'+str(ker_size[i])+'_'+str(N_latent)+'_weights.h5')\n",
    "\n",
    "                optimizer.learning_rate = optimizer.learning_rate*lrate_mult\n",
    "                optimizer.set_weights(min_weights)\n",
    "                print('LEARNING RATE CHANGE', optimizer.learning_rate.numpy(), deviation)\n",
    "                old_loss[epoch-N_lr:epoch] = 1e6 #so that l_rate is not changed for N_lr steps\n",
    "        \n",
    "        #store current loss\n",
    "        old_loss[epoch] = tloss_plot[epoch].copy()\n",
    "        \n",
    "        #save best model (the one with minimum validation loss)\n",
    "        if epoch > 1 and vloss_plot[epoch] < \\\n",
    "                         (vloss_plot[:epoch-1][np.nonzero(vloss_plot[:epoch-1])]).min():\n",
    "        \n",
    "            last_save = epoch #store the last time the val loss has decreased for early stop\n",
    "            \n",
    "        # Print loss values and training time (per epoch)\n",
    "        print('Epoch', epoch, '; Train_Loss', tloss_plot[epoch], \n",
    "              '; Val_Loss', vloss_plot[epoch],  '; Ratio', (vloss_plot[epoch])/(tloss_plot[epoch]))\n",
    "        print('Time per epoch', (time.time()-t)/N_check)\n",
    "        print('')\n",
    "        \n",
    "        t = time.time()\n",
    "\n",
    "enc_mods[0].save(path + '/enc_mod_single_test.h5')\n",
    "enc_mods[0].save_weights(path + '/enc_mod_single_test_weights.h5')\n",
    "\n",
    "#saving the model weights\n",
    "print('Saving Model..')\n",
    "Path(path).mkdir(parents=True, exist_ok=True) #creates directory even when it exists\n",
    "for i in range(N_parallel):\n",
    "    enc_mods[i].save(path + '/enc_mod'+str(ker_size[i])+'_'+str(N_latent)+'.h5')\n",
    "    dec_mods[i].save(path + '/dec_mod'+str(ker_size[i])+'_'+str(N_latent)+'.h5')\n",
    "    enc_mods[i].save_weights(path + '/enc_mod'+str(ker_size[i])+'_'+str(N_latent)+'_weights.h5')\n",
    "    dec_mods[i].save_weights(path + '/dec_mod'+str(ker_size[i])+'_'+str(N_latent)+'_weights.h5')\n",
    "\n",
    "print('Model saved')\n",
    "#plot convergence of training and validation loss (to visualise convergence during training)\n",
    "plt.title('MSE convergence')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, axis=\"both\", which='both', ls=\"-\", alpha=0.3)\n",
    "plt.plot(tloss_plot[np.nonzero(tloss_plot)], 'y', label='Train loss')\n",
    "plt.plot(np.arange(np.nonzero(vloss_plot)[0].shape[0])*N_check, vloss_plot[np.nonzero(vloss_plot)], label='Val loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8cee80fba0cc06",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Visualize error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c6c933e765a4b30",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models: encoder -> ./data/48_RE30_18/enc_mod(3, 3)_18.h5, decoder -> ./data/48_RE30_18/dec_mod(3, 3)_18.h5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error loading models: Unable to synchronously open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 19\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     a[i] \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPerPad2D\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPerPad2D\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     b[i] \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(dec_path, custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerPad2D\u001b[39m\u001b[38;5;124m\"\u001b[39m: PerPad2D})\n",
      "File \u001b[1;32mc:\\Users\\reinm\\anaconda3\\envs\\precursor_legacy\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\reinm\\anaconda3\\envs\\precursor_legacy\\lib\\site-packages\\h5py\\_hl\\files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\reinm\\anaconda3\\envs\\precursor_legacy\\lib\\site-packages\\h5py\\_hl\\files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    230\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 231\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to synchronously open file (file signature not found)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m         b[i] \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(dec_path, custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerPad2D\u001b[39m\u001b[38;5;124m\"\u001b[39m: PerPad2D})\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 22\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel files not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menc_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdec_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error loading models: Unable to synchronously open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TODO: change path\n",
    "'''\n",
    "\n",
    "#load model for the test set\n",
    "path = './data/48_RE30_'+str(N_latent)\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "a = [None] * N_parallel\n",
    "b = [None] * N_parallel\n",
    "\n",
    "for i in range(N_parallel):\n",
    "    enc_path = f\"{path}/enc_mod{ker_size[i]}_{N_latent}.h5\"\n",
    "    dec_path = f\"{path}/dec_mod{ker_size[i]}_{N_latent}.h5\"\n",
    "    print(f\"Loading models: encoder -> {enc_path}, decoder -> {dec_path}\")\n",
    "\n",
    "    if os.path.exists(enc_path) and os.path.exists(dec_path):\n",
    "        try:\n",
    "            a[i] = tf.keras.models.load_model(enc_path, custom_objects={\"PerPad2D\": PerPad2D})\n",
    "            b[i] = tf.keras.models.load_model(dec_path, custom_objects={\"PerPad2D\": PerPad2D})\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading models: {e}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model files not found: {enc_path}, {dec_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343775d2a799f33",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grid\n",
    "X       = np.linspace(0,2*np.pi,N_x) \n",
    "Y       = np.linspace(0,2*np.pi,N_y) \n",
    "XX      = np.meshgrid(X, Y, indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1294525edbb68e86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot n snapshots and their reconstruction in the test set.\n",
    "n       = 5\n",
    "plt.rcParams[\"figure.figsize\"] = (15,4*n)\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "fig, ax = plt.subplots(n,3)\n",
    "\n",
    "start   = b_size*n_batches*skip+b_size*val_batches*skip #start after validation set\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    #truth\n",
    "    plt.subplot(n,3,i*3+1)\n",
    "    \n",
    "    skips = 50\n",
    "    \n",
    "    #snapshots to plot\n",
    "    u      = U[start+500+i*skips:start+501+i*skips].copy()      \n",
    "    vmax   = u.max()\n",
    "    vmin   = u.min()\n",
    "\n",
    "    CS0    = plt.contourf(XX[0], XX[1],u[0,:,:,0],\n",
    "                          levels=10,cmap='coolwarm',vmin=vmin, vmax=vmax)\n",
    "    cbar   = plt.colorbar()\n",
    "    cbar.set_label('$u_{\\mathrm{True}}$',labelpad=15)\n",
    "    CS     = plt.contour(XX[0], XX[1],u[0,:,:,0],\n",
    "                         levels=10,colors='black',linewidths=.5, linestyles='solid',\n",
    "                         vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    #autoencoded\n",
    "    plt.subplot(n,3,i*3+2)\n",
    "\n",
    "    u_dec  = model(u,a,b)[1][0].numpy()\n",
    "    CS     = plt.contourf(XX[0],XX[1],u_dec[:,:,0],\n",
    "                        levels=10,cmap='coolwarm',vmin=vmin, vmax=vmax)\n",
    "    cbar   = plt.colorbar()\n",
    "    cbar.set_label('$u_{\\mathrm{Autoencoded}}$',labelpad=15)\n",
    "    CS     = plt.contour(XX[0], XX[1],u_dec[:,:,0],\n",
    "                         levels=10,colors='black',linewidths=.5, linestyles='solid',\n",
    "                         vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    #error\n",
    "    plt.subplot(n,3,i*3+3)\n",
    "\n",
    "    u_err  = np.abs(u_dec-u[0])/(vmax-vmin)\n",
    "    print('NMAE: ', u_err[:,:,0].mean())\n",
    "    \n",
    "    CS     = plt.contourf(XX[0], XX[1],u_err[:,:,0],levels=10,cmap='coolwarm')\n",
    "    cbar   = plt.colorbar()\n",
    "    cbar.set_label('Relative Error',labelpad=15)\n",
    "    CS     = plt.contour(XX[0], XX[1],u_err[:,:,0],levels=10,colors='black',linewidths=.5, \n",
    "                         linestyles='solid')\n",
    "\n",
    "fig.tight_layout(pad=0.1)\n",
    "plt.savefig(path+'/Autoencoder_error.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd0737aa30b6ae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save Encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd58ade80fca017",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: change path and parameters\n",
    "'''\n",
    "# save the encoded data for the ESN (too much memory used for GPU)\n",
    "N_pos     = 5000 #split in k interval of N_pos length needed to process long timeseries\n",
    "k         = 75\n",
    "transient = 10000\n",
    "N_len = k*N_pos\n",
    "fln      = '/data/ar994/Python/data/Kolmogorov/Kolmogorov_0.1_48_30.0_100100_32.h5'\n",
    "hf       = h5py.File(fln,'r')\n",
    "dt       = 0.1\n",
    "U        = np.array(hf.get('U')[transient:transient+N_len], dtype=np.float32)\n",
    "hf.close()\n",
    "\n",
    "N_x      = U.shape[1]\n",
    "N_y      = U.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d64a9be0d48d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: change parameters\n",
    "'''\n",
    "\n",
    "Latents  = [18]\n",
    "Re       = 30\n",
    "\n",
    "for N_latent in Latents:\n",
    "    path = './data/48_RE30_'+str(N_latent)\n",
    "    a = [None]*N_parallel\n",
    "    b = [None]*N_parallel\n",
    "    for i in range(N_parallel):\n",
    "        a[i] = tf.keras.models.load_model(path + '/enc_mod'+str(ker_size[i])+'_'+str(N_latent)+'.h5', \n",
    "                                              custom_objects={\"PerPad2D\": PerPad2D})\n",
    "    for i in range(N_parallel):\n",
    "        b[i] = tf.keras.models.load_model(path + '/dec_mod'+str(ker_size[i])+'_'+str(N_latent)+'.h5',\n",
    "                                              custom_objects={\"PerPad2D\": PerPad2D})\n",
    "\n",
    "    N_1   = [3,3,N_latent//9]\n",
    "    U_enc = np.zeros((N_len, N_1[0], N_1[1], N_1[2]))\n",
    "    #encode all the data to provide time series in latent space for the ESN\n",
    "    for i in range(k):\n",
    "        U_enc[i*N_pos:(i+1)*N_pos]= model(U[i*N_pos:(i+1)*N_pos], a, b)[0]\n",
    "\n",
    "    fln = './data/48_Encoded_data_Re30_' \\\n",
    "                + str(N_latent) +'.h5'\n",
    "    hf = h5py.File(fln,'w')\n",
    "    hf.create_dataset('U_enc'      ,data=U_enc)  \n",
    "    hf.close()\n",
    "    print(fln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c645918c17745",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient(U,dx,dy,n_splits):\n",
    "    '''Returns dissipation of U, done in n_splits'''\n",
    "    \n",
    "    shapes    = np.array(U.shape)\n",
    "    shapes[0] = shapes[0]//n_splits\n",
    "    dU_dx     = np.empty(shapes)\n",
    "    dU_dy     = np.empty(shapes)\n",
    "    D         = np.empty(shapes[0]*n_splits)\n",
    "    \n",
    "    for i in np.arange(n_splits):\n",
    "        \n",
    "        for j in range(shapes[1]):\n",
    "            dU_dx[:,j] = (U[i*shapes[0]:(i+1)*shapes[0],(j+1)%shapes[1]] - \\\n",
    "                          U[i*shapes[0]:(i+1)*shapes[0],j-1])/(2*dx)\n",
    "        for k in range(shapes[2]):\n",
    "            dU_dy[:,:,k] = (U[i*shapes[0]:(i+1)*shapes[0],:,(k+1)%shapes[2]] - \\\n",
    "                            U[i*shapes[0]:(i+1)*shapes[0],:,k-1])/(2*dy)\n",
    "            \n",
    "        D[i*shapes[0]:(i+1)*shapes[0]] =  np.mean(dU_dx**2+dU_dy**2,\n",
    "                                            axis=(1,2,3))/Re*4\n",
    "              \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d267c18b220b4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,4)\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "#plot average dissipation rate\n",
    "plt.subplot(121)\n",
    "leng      = 5000\n",
    "dx        = 2*np.pi/(N_x-1)\n",
    "DD        = gradient(U[-leng:],dx,dx,1) #true\n",
    "U_dec     = model(U[-leng:], a, b)[1]\n",
    "DD_enc    = gradient(U_dec,dx,dx,1) #autoencoded\n",
    "plt.plot(DD,'w')\n",
    "plt.plot(DD_enc,'r--')\n",
    "\n",
    "#plot error\n",
    "plt.subplot(122)\n",
    "plt.plot(np.abs(DD_enc-DD)/(DD.max()-DD.min()))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(np.mean(np.abs(DD_enc-DD)/(DD.max()-DD.min())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d59000710bfb33",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: implement decoding\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "precursor_legacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
